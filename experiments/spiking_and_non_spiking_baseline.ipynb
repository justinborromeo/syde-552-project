{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_spiking\n",
    "import tensorflow as tf"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion MNIST\n",
    "(\n",
    "    (train_images, train_labels),\n",
    "    (test_images, test_labels),\n",
    ") = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize images so values are between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6334 - accuracy: 0.7816\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3834 - accuracy: 0.8618\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3375 - accuracy: 0.8771\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3097 - accuracy: 0.8873\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2936 - accuracy: 0.8925\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2745 - accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2615 - accuracy: 0.9030\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2524 - accuracy: 0.9074\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2483 - accuracy: 0.9074\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2349 - accuracy: 0.9114\n",
      "313/313 - 1s - loss: 0.3401 - accuracy: 0.8836\n",
      "\n",
      "Test accuracy: 0.8835999965667725\n"
     ]
    }
   ],
   "source": [
    "# Non-spiking\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def train(input_model, train_x, test_x):\n",
    "    input_model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    input_model.fit(train_x, train_labels, epochs=10)\n",
    "\n",
    "    _, test_acc = input_model.evaluate(test_x, test_labels, verbose=2)\n",
    "\n",
    "    print(\"\\nTest accuracy:\", test_acc)\n",
    "\n",
    "\n",
    "train(model, train_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the images for n_steps\n",
    "n_steps = 10\n",
    "train_sequences = np.tile(train_images[:, None], (1, n_steps, 1, 1))\n",
    "test_sequences = np.tile(test_images[:, None], (1, n_steps, 1, 1))\n",
    "spiking_model = tf.keras.Sequential(\n",
    "    [\n",
    "        # add temporal dimension to the input shape; we can set it to None,\n",
    "        # to allow the model to flexibly run for different lengths of time\n",
    "        tf.keras.layers.Reshape((-1, 28 * 28), input_shape=(None, 28, 28)),\n",
    "        # we can use Keras' TimeDistributed wrapper to allow the Dense layer\n",
    "        # to operate on temporal data\n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(128)),\n",
    "        # replace the \"relu\" activation in the non-spiking model with a\n",
    "        # spiking equivalent\n",
    "        keras_spiking.SpikingActivation(\"relu\", spiking_aware_training=False),\n",
    "        # use average pooling layer to average spiking output over time\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# train the model, identically to the non-spiking version,\n",
    "# except using the time sequences as inputs\n",
    "train(spiking_model, train_sequences, test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}