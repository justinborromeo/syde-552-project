{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "separated-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras_spiking\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fuzzy-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Digits Dataset\n",
    "((train_images, train_labels),(test_images, test_labels),) = tf.keras.datasets.mnist.load_data()\n",
    "#train_labels = train_labels.squeeze()\n",
    "#test_labels = test_labels.squeeze()\n",
    "\n",
    "# maximum of each colour is 255\n",
    "#print(np.max(train_images[0], axis=(0,1)))\n",
    "\n",
    "# normalize images so values are between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "#class_names = [\n",
    "#    \"airplane\",\n",
    "#    \"automobile\",\n",
    "#    \"bird\",\n",
    "#    \"cat\",\n",
    "#    \"deer\",\n",
    "#    \"dog\",\n",
    "#    \"frog\",\n",
    "#    \"horse\",\n",
    "#    \"ship\",\n",
    "#    \"truck\",\n",
    "#]\n",
    "\n",
    "class_names = [\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\"\n",
    "]\n",
    "\n",
    "num_classes = len(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "collected-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "worthy-strategy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 22s 11ms/step - loss: 0.3507 - accuracy: 0.8939\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0440 - accuracy: 0.9867\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0321 - accuracy: 0.9896\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0234 - accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0176 - accuracy: 0.9946\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0138 - accuracy: 0.9952\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0127 - accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0095 - accuracy: 0.9970\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0086 - accuracy: 0.9976\n",
      "313/313 - 1s - loss: 0.0336 - accuracy: 0.9923\n",
      "\n",
      "Test accuracy: 0.9922999739646912\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "        \n",
    "        #tf.keras.layers.Flatten(input_shape=train_images.shape[1:]),\n",
    "        #tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        #tf.keras.layers.Dense(num_classes),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def train(input_model, train_x, test_x):\n",
    "    input_model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    input_model.fit(train_x, train_labels, epochs=10)\n",
    "\n",
    "    _, test_acc = input_model.evaluate(test_x, test_labels, verbose=2)\n",
    "\n",
    "\n",
    "    print(\"\\nTest accuracy:\", test_acc)\n",
    "\n",
    "\n",
    "train(model, train_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opposed-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the images for n_steps\n",
    "n_steps = 10\n",
    "train_sequences = np.tile(train_images[:, None], (1, n_steps, 1, 1, 1))\n",
    "test_sequences = np.tile(test_images[:, None], (1, n_steps, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-windsor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 518s 275ms/step - loss: 3.9617 - accuracy: 0.5447\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 525s 280ms/step - loss: 0.3393 - accuracy: 0.9038\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 562s 300ms/step - loss: 0.2054 - accuracy: 0.9387\n",
      "Epoch 4/10\n",
      " 475/1875 [======>.......................] - ETA: 6:51 - loss: 0.1522 - accuracy: 0.9538"
     ]
    }
   ],
   "source": [
    "spikeaware_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(32, (3, 3), input_shape=(28, 28, 1))),\n",
    "        keras_spiking.SpikingActivation(\"relu\", dt=0.01, spiking_aware_training=True),\n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D((2, 2))),\n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(64, (3, 3))),\n",
    "        keras_spiking.SpikingActivation(\"relu\", dt=0.01, spiking_aware_training=True),\n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D((2, 2))),\n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(64, (3, 3))),\n",
    "        \n",
    "        tf.keras.layers.Reshape((-1, 3 * 3 * 64), input_shape=(None,10,3,3,64)),\n",
    "        keras_spiking.SpikingActivation(\"relu\", dt=0.01, spiking_aware_training=True),\n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64)),\n",
    "        # set spiking_aware training and a moderate dt\n",
    "        keras_spiking.SpikingActivation(\"relu\", dt=0.01, spiking_aware_training=True),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# train the model, identically to the non-spiking version,\n",
    "# except using the time sequences as inputs\n",
    "train(spikeaware_model, train_sequences, test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-accident",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
